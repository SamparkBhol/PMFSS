{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_training.ipynb\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import joblib\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "\n",
    "# Load configuration\n",
    "with open(\"../config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Configure logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"Model Training\")\n",
    "\n",
    "# Load the cleaned data\n",
    "cleaned_data_path = config[\"data\"][\"cleaned_data_path\"]\n",
    "data = pd.read_csv(cleaned_data_path)\n",
    "logger.info(f\"Cleaned data loaded successfully from {cleaned_data_path}\")\n",
    "\n",
    "# Split the data into training and test sets\n",
    "target_column = config[\"data\"][\"target_column\"]\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "logger.info(\"Data split into training and test sets\")\n",
    "\n",
    "# Define the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", eval_metric=\"auc\", use_label_encoder=False)\n",
    "logger.info(\"XGBoost model initialized\")\n",
    "\n",
    "# Define hyperparameters for tuning\n",
    "param_grid = {\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"subsample\": [0.7, 0.8, 0.9],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "# Perform grid search for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring=\"roc_auc\", verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "logger.info(\"Grid search completed for hyperparameter tuning\")\n",
    "\n",
    "# Retrieve the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "logger.info(f\"Best model parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "logger.info(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "logger.info(f\"Model AUC Score: {auc:.4f}\")\n",
    "logger.info(f\"Classification Report:\\n{report}\")\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the ROC curve\n",
    "xgb.plot_importance(best_model, importance_type=\"gain\", max_num_features=10)\n",
    "plt.title(\"Top 10 Feature Importances by Gain\")\n",
    "plt.show()\n",
    "\n",
    "# Save the trained model\n",
    "model_path = config[\"model\"][\"path\"]\n",
    "joblib.dump(best_model, model_path)\n",
    "logger.info(f\"Trained model saved to {model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
